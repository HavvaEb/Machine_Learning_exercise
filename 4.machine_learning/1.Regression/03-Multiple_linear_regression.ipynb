{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike the simple linear regression model, the multiple linear regression model is defined as any linear regression model with at least two explanatory variables. But what do we do when we have several variables? This is what we will see in this chapter. And you will finally be able to measure all the power of linear regression despite its simplicity!\n",
    "\n",
    "\n",
    "## Variables studied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we will load our dataset. This is a fake Dataset for the example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./data/data_multi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.054452</td>\n",
       "      <td>-1.070753</td>\n",
       "      <td>-81.464433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.362741</td>\n",
       "      <td>-0.634322</td>\n",
       "      <td>-78.752795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.854096</td>\n",
       "      <td>0.313068</td>\n",
       "      <td>2.218414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.326386</td>\n",
       "      <td>0.298238</td>\n",
       "      <td>52.234160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.461585</td>\n",
       "      <td>-1.315907</td>\n",
       "      <td>-159.639258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.943621</td>\n",
       "      <td>-1.173123</td>\n",
       "      <td>-51.806001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.602058</td>\n",
       "      <td>0.625231</td>\n",
       "      <td>82.457071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.401781</td>\n",
       "      <td>0.177426</td>\n",
       "      <td>-10.956509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.977278</td>\n",
       "      <td>1.867558</td>\n",
       "      <td>184.086053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.378163</td>\n",
       "      <td>0.154947</td>\n",
       "      <td>13.651390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.302303</td>\n",
       "      <td>-0.387327</td>\n",
       "      <td>-47.357790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.747455</td>\n",
       "      <td>-0.413619</td>\n",
       "      <td>-71.204074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.187184</td>\n",
       "      <td>0.045759</td>\n",
       "      <td>-15.059425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.318728</td>\n",
       "      <td>0.920859</td>\n",
       "      <td>116.157625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-1.536244</td>\n",
       "      <td>0.465662</td>\n",
       "      <td>-12.005370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.400157</td>\n",
       "      <td>1.764052</td>\n",
       "      <td>170.305651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.826439</td>\n",
       "      <td>-0.744755</td>\n",
       "      <td>-80.972620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.742165</td>\n",
       "      <td>0.864436</td>\n",
       "      <td>70.987642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.706573</td>\n",
       "      <td>0.356366</td>\n",
       "      <td>87.311098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.900826</td>\n",
       "      <td>-1.165150</td>\n",
       "      <td>-104.885690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.578850</td>\n",
       "      <td>-0.870797</td>\n",
       "      <td>-87.888333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.208299</td>\n",
       "      <td>0.576591</td>\n",
       "      <td>40.052386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.681595</td>\n",
       "      <td>-1.034243</td>\n",
       "      <td>-43.240607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.802456</td>\n",
       "      <td>-0.268003</td>\n",
       "      <td>-43.837573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.777490</td>\n",
       "      <td>-1.252795</td>\n",
       "      <td>-83.352311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-1.544771</td>\n",
       "      <td>-1.000215</td>\n",
       "      <td>-95.253147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.969397</td>\n",
       "      <td>-1.270485</td>\n",
       "      <td>-111.165528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.676433</td>\n",
       "      <td>-0.635846</td>\n",
       "      <td>-38.749853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.785870</td>\n",
       "      <td>0.010500</td>\n",
       "      <td>28.782872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.543015</td>\n",
       "      <td>-0.739563</td>\n",
       "      <td>-30.140956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>1.480515</td>\n",
       "      <td>1.922942</td>\n",
       "      <td>248.973825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.316943</td>\n",
       "      <td>1.188030</td>\n",
       "      <td>132.130618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>-2.223403</td>\n",
       "      <td>-0.643618</td>\n",
       "      <td>-141.298982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>1.713343</td>\n",
       "      <td>-0.068242</td>\n",
       "      <td>31.761874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.302472</td>\n",
       "      <td>0.066517</td>\n",
       "      <td>-2.684307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.121675</td>\n",
       "      <td>0.761038</td>\n",
       "      <td>76.031909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>-1.420018</td>\n",
       "      <td>-1.048553</td>\n",
       "      <td>-171.027947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.439392</td>\n",
       "      <td>-1.491258</td>\n",
       "      <td>-118.641383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>-0.179925</td>\n",
       "      <td>1.178780</td>\n",
       "      <td>99.200909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>-0.684810</td>\n",
       "      <td>0.402342</td>\n",
       "      <td>-43.403402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>-1.099401</td>\n",
       "      <td>0.376426</td>\n",
       "      <td>-31.574759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>-0.151357</td>\n",
       "      <td>0.950088</td>\n",
       "      <td>106.628510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>-0.437820</td>\n",
       "      <td>-1.147469</td>\n",
       "      <td>-61.235202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.051945</td>\n",
       "      <td>-0.907298</td>\n",
       "      <td>-120.444231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>-1.093062</td>\n",
       "      <td>0.396007</td>\n",
       "      <td>9.081810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.407462</td>\n",
       "      <td>0.672295</td>\n",
       "      <td>18.485981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.539249</td>\n",
       "      <td>-0.769916</td>\n",
       "      <td>-52.643638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>1.910065</td>\n",
       "      <td>-0.861226</td>\n",
       "      <td>-48.810278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.428332</td>\n",
       "      <td>-0.028182</td>\n",
       "      <td>16.768090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.653619</td>\n",
       "      <td>-2.552990</td>\n",
       "      <td>-199.180705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.944479</td>\n",
       "      <td>2.383145</td>\n",
       "      <td>315.513469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.031831</td>\n",
       "      <td>-0.674333</td>\n",
       "      <td>-48.219859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>1.929532</td>\n",
       "      <td>-0.498032</td>\n",
       "      <td>5.147029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>-1.454366</td>\n",
       "      <td>2.269755</td>\n",
       "      <td>199.436860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.462782</td>\n",
       "      <td>-1.630198</td>\n",
       "      <td>-130.813139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.823504</td>\n",
       "      <td>0.771791</td>\n",
       "      <td>86.316340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.976639</td>\n",
       "      <td>0.208275</td>\n",
       "      <td>83.136943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-1.347759</td>\n",
       "      <td>1.883151</td>\n",
       "      <td>157.404615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.052165</td>\n",
       "      <td>-1.104383</td>\n",
       "      <td>-136.511136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>-1.726283</td>\n",
       "      <td>-0.813146</td>\n",
       "      <td>-143.452015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         x_1       x_2           y\n",
       "0   1.054452 -1.070753  -81.464433\n",
       "1  -0.362741 -0.634322  -78.752795\n",
       "2  -0.854096  0.313068    2.218414\n",
       "3   1.326386  0.298238   52.234160\n",
       "4  -0.461585 -1.315907 -159.639258\n",
       "5   1.943621 -1.173123  -51.806001\n",
       "6  -1.602058  0.625231   82.457071\n",
       "7  -0.401781  0.177426  -10.956509\n",
       "8  -0.977278  1.867558  184.086053\n",
       "9   0.378163  0.154947   13.651390\n",
       "10 -0.302303 -0.387327  -47.357790\n",
       "11 -0.747455 -0.413619  -71.204074\n",
       "12 -0.187184  0.045759  -15.059425\n",
       "13  0.318728  0.920859  116.157625\n",
       "14 -1.536244  0.465662  -12.005370\n",
       "15  0.400157  1.764052  170.305651\n",
       "16 -0.826439 -0.744755  -80.972620\n",
       "17 -0.742165  0.864436   70.987642\n",
       "18  0.706573  0.356366   87.311098\n",
       "19  0.900826 -1.165150 -104.885690\n",
       "20 -0.578850 -0.870797  -87.888333\n",
       "21 -0.208299  0.576591   40.052386\n",
       "22  0.681595 -1.034243  -43.240607\n",
       "23  0.802456 -0.268003  -43.837573\n",
       "24  0.777490 -1.252795  -83.352311\n",
       "25 -1.544771 -1.000215  -95.253147\n",
       "26  0.969397 -1.270485 -111.165528\n",
       "27  0.676433 -0.635846  -38.749853\n",
       "28  1.785870  0.010500   28.782872\n",
       "29  1.543015 -0.739563  -30.140956\n",
       "..       ...       ...         ...\n",
       "70  1.480515  1.922942  248.973825\n",
       "71  0.316943  1.188030  132.130618\n",
       "72 -2.223403 -0.643618 -141.298982\n",
       "73  1.713343 -0.068242   31.761874\n",
       "74  0.302472  0.066517   -2.684307\n",
       "75  0.121675  0.761038   76.031909\n",
       "76 -1.420018 -1.048553 -171.027947\n",
       "77  0.439392 -1.491258 -118.641383\n",
       "78 -0.179925  1.178780   99.200909\n",
       "79 -0.684810  0.402342  -43.403402\n",
       "80 -1.099401  0.376426  -31.574759\n",
       "81 -0.151357  0.950088  106.628510\n",
       "82 -0.437820 -1.147469  -61.235202\n",
       "83  0.051945 -0.907298 -120.444231\n",
       "84 -1.093062  0.396007    9.081810\n",
       "85  0.407462  0.672295   18.485981\n",
       "86  0.539249 -0.769916  -52.643638\n",
       "87  1.910065 -0.861226  -48.810278\n",
       "88  0.428332 -0.028182   16.768090\n",
       "89  0.653619 -2.552990 -199.180705\n",
       "90  0.944479  2.383145  315.513469\n",
       "91  0.031831 -0.674333  -48.219859\n",
       "92  1.929532 -0.498032    5.147029\n",
       "93 -1.454366  2.269755  199.436860\n",
       "94  0.462782 -1.630198 -130.813139\n",
       "95  0.823504  0.771791   86.316340\n",
       "96  0.976639  0.208275   83.136943\n",
       "97 -1.347759  1.883151  157.404615\n",
       "98  0.052165 -1.104383 -136.511136\n",
       "99 -1.726283 -0.813146 -143.452015\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see we now have 100 rows, 2 features and 1 target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise :** Create the `X` and `y` variables and define which column will be the target and which column will be the feature. \n",
    "They must be of type `numpy.ndarray`. Our variable `X` has two dimensions this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "y= np.array(df.y)\n",
    "X = np.array(df.x_1, df.x_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relationship between variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To represent a dataset that has two features, we can use 3D visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise :** Use a 3D matplotlib (or other) graph to view the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you change the camera angle, you should come across something that looks like this: \n",
    "<img src=\"./assets/3dplot.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This appears to be a positive linear correlation. What do you say?  \n",
    "\n",
    "\n",
    "If our dataset has more than two dimensions, then we won't be able to display it in 3D. Unfortunately for us, the human being can only perceive 3 dimensions. In this case, we will have no other choice than to display one scatter plot per variable.\n",
    "\n",
    "And it is there that we realize that the linear regression may be very simple, as soon as we go beyond 3 dimensions, the human being will hardly be able to visualize all the data while the machines are doing very well.\n",
    "\n",
    "**Exercise :** Create a scatter plot for each variable with respect to the target. You may use  `plt.tight_layout()` after plotting if the graph is too cramped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise :** Show correlation coefficients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset\n",
    "\n",
    "You now know the process!\n",
    "\n",
    "**Exercise :** Import `train_test_split` from `sklearn` and split the dataset and create the variables `X_train`, `X_test`, `y_train`, `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Load and fit the model (with Sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to use `sklearn` now with multiple features ? Well, it's simple, you don't change anything. `sklearn` takes care of everything for you.\n",
    "\n",
    "1. Import `LinearRegression` from `sklearn`\n",
    "2. Create a `regressor` variable and instantiate your `LinearRegression` class.\n",
    "3. Train your model with `X_train` and `y_train`.\n",
    "4. Display the score of your model with `X_train` and `y_train`.\n",
    "5. Use the predict method of your model on your test dataset (`X_test`).\n",
    "6. Display the score of your model with `X_test` and `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And voilà !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Scratch \n",
    "You will see that with matrices, it doesn't change much in the way of proceeding. Matrix writing, moreover, remains the same as simple regression. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform to matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\\\ Y = X \\cdot \\theta \\\\\n",
    "$$\n",
    "The $Y$ vector is the same too\n",
    "$$ Y =\n",
    "\\begin{bmatrix}\n",
    "y^{(1)}\\\\\n",
    "y^{(2)}\\\\\n",
    "y^{(3)}\\\\\n",
    "... \\\\\n",
    "y^{(m)}\\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $X$ matrix will have as many dimensions as there are features +1  (n+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ X =\n",
    "\\begin{bmatrix}\n",
    "x^{(1)}_1, x^{(1)}_2, ..., x^{(m)}_{n}, 1\\\\\n",
    "x^{(2)}_1, x^{(2)}_2, ..., x^{(m)}_{n}, 1\\\\\n",
    "x^{(3)}_1, x^{(3)}_2, ..., x^{(m)}_{n}, 1\\\\\n",
    "x^{(m)}_1,x^{(m)}_2, ..., x^{(m)}_{n}, 1\\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The theta vector will have as many lines as there are parameters +1 (for the constant). \n",
    "$$ \\theta =\n",
    "\\begin{bmatrix}\n",
    "a\\\\\n",
    "b\\\\\n",
    "c\\\\\n",
    "... \\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our case with our dataset, we can write it like this: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{bmatrix}\n",
    "y^{(1)}\\\\\n",
    "y^{(2)}\\\\\n",
    "y^{(3)}\\\\\n",
    "... \\\\\n",
    "y^{(m)}\\\\\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "x^{(1)}_1, x^{(1)}_2, 1\\\\\n",
    "x^{(2)}_1, x^{(2)}_2, 1\\\\\n",
    "x^{(3)}_1, x^{(3)}_2, 1\\\\\n",
    "x^{(m)}_1,x^{(m)}_2,  1\\\\\n",
    "\\end{bmatrix}\n",
    "\\cdot\n",
    "\\begin{bmatrix}\n",
    "a\\\\\n",
    "b\\\\\n",
    "c\\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise :** Create a variable `X` which contains a matrix of shape `(100,3)` with two column's filled with values of our dataframe and then another one with 1's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise :** Check that your matrix is of shape `(100,3)`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise :** Create the theta vector with three random values. Your vector must be of shape \n",
    "`(3,1)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and fit the model\n",
    "### Define your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise :** Create a `model` function that receives as parameter `X` and `theta`. The function must return the computed predictions `y_pred`. This is exactly the same model as last time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well we have the model, the $\\theta$ vector, the $X$ matrix. What are we missing? The cost function of course!\n",
    "And you know what? This too is exactly the same MSE function from last time. \n",
    "\n",
    "$$MSE(\\theta) = \\frac {1}{2m}  \\sum (X \\cdot \\theta - Y)^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise :** Create a MSE function that receives as parameters `X`, `y` and `theta` using the example above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient descent\n",
    "It's time to find the minimum of our function. Well again, nothing changes compared to the last time. \n",
    "\n",
    "$$ \\frac {\\partial MSE(\\theta) }{\\partial \\theta}  = \\frac {1}{m} X^T \\cdot (X \\cdot \\theta - Y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise :** Create a `grad` function that receives as parameter `X`, `y`, `theta`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise :**\n",
    "\n",
    "1. Create a `gradient_descent` function that receives as parameter `X`, `y`, `theta`, `learning_rate`, `n_iterations`.\n",
    "2. In the function, create a variable `cost_history` with a matrix filled with 0 and which has a length of `n_iterations`. We will use it to display the histogram of the model learning process.\n",
    "3. Create a loop that iterates up to `n_iterations`.\n",
    "4. In the loop, update `theta` with the formula of the gradient descent (the example above).\n",
    "5. In the loop, update `cost_history[i]` with the values of `MSE(X,y,theta)`.\n",
    "6. return `theta` and `cost_history`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, theta, learning_rate, n_iterations):\n",
    "    cost_history = np.zeros(n_iterations)\n",
    "    for i in range(n_iterations):\n",
    "        print(i)\n",
    "        theta = theta - learning_rate * grad(X, y, theta)\n",
    "        cost_history[i] = MSE(X,y,theta) # values of MSE\n",
    "        \n",
    "         #cost_history.append(computeCost(X, y, theta))\n",
    "    return theta, cost_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train your model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise :** Create variables `n_iterations` and `learning_rate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_target' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-11ab36111939>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mn_iterations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.01\u001b[0m \u001b[1;31m#alpha\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_target\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'y_target' is not defined"
     ]
    }
   ],
   "source": [
    "n_iterations = 1000\n",
    "learning_rate = 0.01 #alpha\n",
    "y=y_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Create variables `theta_final`, `cost_history` and call `gradient_descent()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_final, cost_history = gradient_descent(X, y, theta, learning_rate, n_iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise :** \n",
    "Create a `predictions` variable that contains `model(X, theta_final)`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=model(X, theta_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise :** Plot your predictions in 3D and the true values of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise :** Plot `cost_history`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coef_determination(y, pred):\n",
    "    u = ((y - pred)**2).sum()\n",
    "    v = ((y - y.mean())**2).sum()\n",
    "    return 1 - u/v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y    0.93205\n",
       "dtype: float64"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_determination(y, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congratulations !\n",
    "\n",
    "You are now able to create a multiple variable regression model from scratch, well, from the matrix!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://media.giphy.com/media/W9lzJDwciz6bS/giphy.gif\">"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dd4aeab626a3aa6146a37463a21e1f94e4c8c94bf8266b94cd66da6f1530ae28"
  },
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
